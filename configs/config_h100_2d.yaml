# config_h100_2d.yaml  –  Optimised for a single NVIDIA H100 80 GB
model:
  vae_base_model: 'medvae_4_1_2d'
  latent_channels: 1
  vae_temporal_weight: 0.1
  freeze_vae_after: 0            # fine-tune a few k steps, then freeze

  # ───────── DiT (backbone) ───────────────────────────────────────────
  dit_config:
    latent_channels: 1
    latent_size: [41, 128, 128]        # 40 frames, 128×128 → 16×16 after 8× down-sampling
    hidden_dim: 256
    depth: 8                 # ~1.1 B parameters – H100 can handle it
    num_heads: 8
    mlp_ratio: 4.0
    dropout: 0.1
    use_rope: true
    gradient_checkpointing: false

  # ───────── Flow-matching objective ─────────────────────────────────
  flow_matching_config:
    num_sampling_steps: 20           # slight increase
    sigma_min: 1e-5
    use_ode_solver: 'euler'
    time_sampling: 'logit_normal'  # More sophisticated
    loss_weighting: 'velocity'
    interpolation_method: 'optimal_transport'
    # The following regularizers as implemented do not backprop through the model; keep at zero
    num_midpoints: 0
    mid_loss_weight: 0.0
    tv_loss_weight: 0.0
training:
  # ───────── Optimisation ╱ regularisation ───────────────────────────
  vae_lr: 5.0e-5
  dit_lr: 5.0e-5                    # lower to stabilise the bigger model
  weight_decay: 0.02
  grad_clip: 1.0

  velocity_weight: 1.0
  flf_weight: 0.1
  vae_recon_weight: 0.5
  vae_kl_weight: 0.01
  vae_temporal_weight: 0.2
  vae_chunk_size: 8 
  finetune_vae: false
  freeze_vae_after: 0
  # auxiliary loss weights (teacher-forcing)
  step_loss_weight: 1.0
  # ───────── Schedule ────────────────────────────────────────────────
  num_epochs: 40
  val_freq: 5
  save_freq: 5
  scheduler_type: 'cosine'
  warmup_epochs: 3

  # ───────── Batch / precision settings for H100-80 GB ───────────────
  batch_size: 4                   # per GPU (8×40×128² fits with fp16)
  gradient_accumulation_steps: 2
  mixed_precision: true             # fp16 + bfloat16 automatically on H100
  gradient_checkpointing: true    # not needed – plenty of VRAM
  compile_model: false

data:
  # Input is a *single* axial slice time-series → 2-D VAE
  num_frames: 41
  input_frames: 10
  target_size: [512, 512]
  slice_mode: 'three_slices'
  slice_indices: [12, 25, 37]
  intensity_window: [-600, 900]
  normalize: true  # Apply lung windowing and normalize to [-1, 1]

  augmentation:
    enable_augmentation: true
    intensity_scale: 0.03
    intensity_shift: 0.03
    noise_std: 0.005
  phase_range: '0-50'  # Full breathing cycle (no filtering)
inference:
  guidance_scale: 1.0
  num_sampling_steps: 60
  batch_size: 4                     # generous for H100
