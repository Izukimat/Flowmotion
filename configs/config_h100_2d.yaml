# config_h100_2d.yaml  –  Optimised for a single NVIDIA H100 80 GB
#
# Key changes vs. the V100 config
# • 2-D MedVAE (8×8 down-sampling) instead of 3-D
# • Larger DiT backbone (depth 32, hidden 1 024) – fits comfortably in 80 GB
# • Higher batch size (8 slices × 40 frames) without gradient-checkpointing
# • Uniform time-sampling keeps things simple; you can switch to logit-normal later

model:
  # ───────── VAE (2-D) ────────────────────────────────────────────────
  vae_base_model: 'medvae_8x1_2d'     # 8× compression per spatial axis (=64× pixel-count)
  latent_channels: 8                  # 1 → 8 channel expansion inside wrapper
  vae_temporal_weight: 0.1
  freeze_vae_after: 5_000            # fine-tune a few k steps, then freeze

  # ───────── DiT (backbone) ───────────────────────────────────────────
  dit_config:
    latent_channels: 8
    latent_size: [40, 16, 16]        # 40 frames, 128×128 → 16×16 after 8× down-sampling
    hidden_dim: 1024
    depth: 32                        # ~1.1 B parameters – H100 can handle it
    num_heads: 16
    mlp_ratio: 4.0
    dropout: 0.05
    use_rope: true

  # ───────── Flow-matching objective ─────────────────────────────────
  flow_matching_config:
    num_sampling_steps: 60           # slight increase
    sigma_min: 1e-5
    use_ode_solver: 'euler'
    time_sampling: 'logit_normal'  # More sophisticated
    loss_weighting: 'velocity'
    interpolation_method: 'optimal_transport'

training:
  # ───────── Optimisation ╱ regularisation ───────────────────────────
  vae_lr: 1.0e-4
  dit_lr: 5.0e-5                    # lower to stabilise the bigger model
  weight_decay: 0.02
  grad_clip: 1.0

  velocity_weight: 1.0
  flf_weight: 0.1
  vae_recon_weight: 1.0
  vae_kl_weight: 0.01
  vae_temporal_weight: 0.1

  # ───────── Schedule ────────────────────────────────────────────────
  num_epochs: 80
  val_freq: 4
  save_freq: 8
  scheduler_type: 'cosine'
  warmup_epochs: 3

  # ───────── Batch / precision settings for H100-80 GB ───────────────
  batch_size: 8                     # per GPU (8×40×128² fits with fp16)
  gradient_accumulation_steps: 1
  mixed_precision: true             # fp16 + bfloat16 automatically on H100
  gradient_checkpointing: false     # not needed – plenty of VRAM

data:
  # Input is a *single* axial slice time-series → 2-D VAE
  num_frames: 40
  target_size: [128, 128]           # resize each slice to 128²
  slice_mode: 'three_slices'        # apex / mid / base
  slice_indices: [10, 25, 40]
  intensity_window: [-1000, 500]

  augmentation:
    enable_augmentation: true
    intensity_scale: 0.05
    intensity_shift: 0.05
    noise_std: 0.01

inference:
  guidance_scale: 1.0
  num_sampling_steps: 60
  batch_size: 4                     # generous for H100
