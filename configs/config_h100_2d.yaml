# config_h100_2d.yaml  –  Optimised for a single NVIDIA H100 80 GB
#
# Key changes vs. the V100 config
# • 2-D MedVAE (8×8 down-sampling) instead of 3-D
# • Larger DiT backbone (depth 32, hidden 1 024) – fits comfortably in 80 GB
# • Higher batch size (8 slices × 40 frames) without gradient-checkpointing
# • Uniform time-sampling keeps things simple; you can switch to logit-normal later

model:
  vae_base_model: 'medvae_4_1_2d'
  latent_channels: 4
  vae_temporal_weight: 0.1
  freeze_vae_after: 5000            # fine-tune a few k steps, then freeze

  # ───────── DiT (backbone) ───────────────────────────────────────────
  dit_config:
    latent_channels: 4
    latent_size: [41, 128, 128]        # 40 frames, 128×128 → 16×16 after 8× down-sampling
    hidden_dim: 128
    depth: 4                 # ~1.1 B parameters – H100 can handle it
    num_heads: 4
    mlp_ratio: 2.0
    dropout: 0.1
    use_rope: true
    gradient_checkpointing: false

  # ───────── Flow-matching objective ─────────────────────────────────
  flow_matching_config:
    num_sampling_steps: 20           # slight increase
    sigma_min: 1e-5
    use_ode_solver: 'euler'
    time_sampling: 'logit_normal'  # More sophisticated
    loss_weighting: 'velocity'
    interpolation_method: 'optimal_transport'

training:
  # ───────── Optimisation ╱ regularisation ───────────────────────────
  vae_lr: 5.0e-5
  dit_lr: 5.0e-5                    # lower to stabilise the bigger model
  weight_decay: 0.02
  grad_clip: 1.0

  velocity_weight: 1.0
  flf_weight: 0.1
  vae_recon_weight: 0.5
  vae_kl_weight: 0.01
  vae_temporal_weight: 0.2
  vae_chunk_size: 8 
  finetune_vae: false
  freeze_vae_after: 5000
  # ───────── Schedule ────────────────────────────────────────────────
  num_epochs: 30
  val_freq: 4
  save_freq: 5
  scheduler_type: 'cosine'
  warmup_epochs: 3

  # ───────── Batch / precision settings for H100-80 GB ───────────────
  batch_size: 2                   # per GPU (8×40×128² fits with fp16)
  gradient_accumulation_steps: 2
  mixed_precision: true             # fp16 + bfloat16 automatically on H100
  gradient_checkpointing: true    # not needed – plenty of VRAM
  compile_model: true

data:
  # Input is a *single* axial slice time-series → 2-D VAE
  num_frames: 41
  input_frames: 10
  target_size: [512, 512]
  slice_mode: 'three_slices'
  slice_indices: [12, 25, 37]
  intensity_window: [-1000, 500]
  normalize: true  # Apply lung windowing and normalize to [-1, 1]

  augmentation:
    enable_augmentation: true
    intensity_scale: 0.03
    intensity_shift: 0.03
    noise_std: 0.005
  phase_range: '0-50'  # Full breathing cycle (no filtering)
inference:
  guidance_scale: 1.0
  num_sampling_steps: 60
  batch_size: 4                     # generous for H100
